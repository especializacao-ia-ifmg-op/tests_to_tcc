{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras-tcn==2.8.3\n",
    "# !git clone https://github.com/PatriciaLucas/CNN\n",
    "# from CNN import Ensemble as es\n",
    "# from CNN import basic\n",
    "import Ensemble as es\n",
    "import basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 7\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import warnings\n",
    "# from google.colab import files\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    mindf = df.min()\n",
    "    maxdf = df.max()\n",
    "    return (df-mindf)/(maxdf-mindf)\n",
    "\n",
    "def denormalize(norm, _min, _max):\n",
    "    return [(n * (_max-_min)) + _min for n in norm]\n",
    "\n",
    "def get_search_dataset_multivariate(dataset, n_var):\n",
    "    df1 = pd.read_csv(dataset, sep=\"\\s+|;|,\") # 7305 registros\n",
    "    \n",
    "    ints = df1.select_dtypes(include=['int64','int32','int16']).columns\n",
    "    df1[ints] = df1[ints].apply(pd.to_numeric, downcast='integer')\n",
    "    floats = df1.select_dtypes(include=['float']).columns\n",
    "    df1[floats] = df1[floats].apply(pd.to_numeric, downcast='float')\n",
    "    \n",
    "    series = df1.iloc[:,1:n_var+1]\n",
    "    norm_df = normalize(series)\n",
    "    size = int(len(norm_df) * 0.80)\n",
    "    train = series[:size]\n",
    "    test = series[size:]\n",
    "    return train, test\n",
    "\n",
    "def form_data(data, t, n_execucoes, n_previsoes):\n",
    "    df = pd.DataFrame(data)\n",
    "    df1 = df.T\n",
    "    frames = [df1.iloc[:,0], df1.iloc[:,1], df1.iloc[:,2], df1.iloc[:,3], df1.iloc[:,4]]#, df1.iloc[:,5], df1.iloc[:,6], df1.iloc[:,7], df1.iloc[:,8], df1.iloc[:,9], df1.iloc[:,10], df1.iloc[:,11],\n",
    "        #  df1.iloc[:,12], df1.iloc[:,13], df1.iloc[:,14], df1.iloc[:,15], df1.iloc[:,16], df1.iloc[:,17],df1.iloc[:,18], df1.iloc[:,19], df1.iloc[:,20], df1.iloc[:,21], df1.iloc[:,22], \n",
    "        #  df1.iloc[:,23], df1.iloc[:,24], df1.iloc[:,25], df1.iloc[:,26], df1.iloc[:,27], df1.iloc[:,28], df1.iloc[:,29]]\n",
    "    result = pd.concat(frames)\n",
    "    r = pd.DataFrame(result) \n",
    "    r.insert(1, \"Model\", True)\n",
    "    for i in range(n_execucoes * n_previsoes): # n_execucoes * n_previsoes\n",
    "        r['Model'].iloc[i] = 'CNN'+ t\n",
    "    return r\n",
    "\n",
    "def run_model(dataset_file_name, result_file_name, sufix, star, n_var, n_execucoes, n_previsoes):\n",
    "    train, test = get_search_dataset_multivariate(dataset_file_name, n_var=n_var)\n",
    "    results = []\n",
    "    train, test, scaler = es.get_dados(star, train, test)\n",
    "    X_train, y_train, X_test, y_test = basic.slideWindowMulti(train, test, n_lags=star['lags'], n_var=n_var)\n",
    "    for i in range(n_execucoes):\n",
    "        model,_ = basic.modelo_CNN1(X_train, y_train, star)\n",
    "        rmse, yhat, y_test = basic.predictModelMulti(test, model, n_previsoes=n_previsoes, n_lags=star['lags'], n_var=n_var, scaler=scaler)\n",
    "        results.append(rmse)\n",
    "\n",
    "    results = form_data(results, sufix, n_execucoes, n_previsoes)\n",
    "    results.to_csv(result_file_name,index=True)\n",
    "    del train\n",
    "    del test\n",
    "    del X_train\n",
    "    del y_train\n",
    "    del X_test\n",
    "    del y_test\n",
    "    del yhat\n",
    "    del model\n",
    "    del results\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_CNN1 = {'filters': 1, 'pool': 0, 'pool_size': 3, 'dropout': 0.012594059561340142, 'norm': 1, 'lags': 4, 'num_conv': 1, 'kernel_size': 3, 'rmse': 0.7696852129001718, 'num_param': 449}\n",
    "# star_CNN2 = {'filters': 1, 'dropout': 0, 'norm': 1, 'lags': 4, 'num_conv': 1, 'kernel_size': 0, 'rmse': 0.7566198577347709, 'num_param': 449}\n",
    "# star_CNN3 = {'pilhas': 2, 'filters': 1, 'dropout': 0.2, 'norm': 1, 'lags': 48, 'num_conv': 3, 'kernel_size': 2, 'rmse': 0.7530, 'num_param': 68257}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(dataset_file_name='uni_lat-19.75_lon-44.45.csv', result_file_name='new_u_results_CNN1.csv', sufix='1 (ETo)', star=star_CNN1, n_var=1, n_execucoes=5, n_previsoes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(dataset_file_name='multi_rs_lat-19.75_lon-44.45.csv', result_file_name='new_m_rs_results_CNN1.csv', sufix='1 (Rs, ETo)', star=star_CNN1, n_var=2, n_execucoes=5, n_previsoes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(dataset_file_name='multi_u2_lat-19.75_lon-44.45.csv', result_file_name='new_m_u2_results_CNN1.csv', sufix='1 (u2, ETo)', star=star_CNN1, n_var=2, n_execucoes=5, n_previsoes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(dataset_file_name='multi_rh_lat-19.75_lon-44.45.csv', result_file_name='new_m_rh_results_CNN1.csv', sufix='1 (RH, ETo)', star=star_CNN1, n_var=2, n_execucoes=5, n_previsoes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(dataset_file_name='multi_tmax_lat-19.75_lon-44.45.csv', result_file_name='new_m_tmax_results_CNN1.csv', sufix='1 (Tmax, ETo)', star=star_CNN1, n_var=2, n_execucoes=5, n_previsoes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_CNN1 = pd.read_csv('new_u_results_CNN1.csv',delimiter=',')\n",
    "u_CNN1 = u_CNN1[u_CNN1['Unnamed: 0'].isin([0,2,6,9])]\n",
    "\n",
    "m_rs_CNN1 = pd.read_csv('new_m_rs_results_CNN1.csv',delimiter=',')\n",
    "m_rs_CNN1 = m_rs_CNN1[m_rs_CNN1['Unnamed: 0'].isin([0,2,6,9])]\n",
    "\n",
    "m_u2_CNN1 = pd.read_csv('new_m_u2_results_CNN1.csv',delimiter=',')\n",
    "m_u2_CNN1 = m_u2_CNN1[m_u2_CNN1['Unnamed: 0'].isin([0,2,6,9])]\n",
    "\n",
    "m_rh_CNN1 = pd.read_csv('new_m_rh_results_CNN1.csv',delimiter=',')\n",
    "m_rh_CNN1 = m_rh_CNN1[m_rh_CNN1['Unnamed: 0'].isin([0,2,6,9])]\n",
    "\n",
    "m_tmax_CNN1 = pd.read_csv('new_m_tmax_results_CNN1.csv',delimiter=',')\n",
    "m_tmax_CNN1 = m_tmax_CNN1[m_tmax_CNN1['Unnamed: 0'].isin([0,2,6,9])]\n",
    "\n",
    "# m_tmin_CNN1 = pd.read_csv('m_tmin_results_CNN1.csv',delimiter=',')\n",
    "# m_tmin_CNN1 = m_tmin_CNN1[m_tmin_CNN1['Unnamed: 0'].isin([0,2,6,9])]\n",
    "\n",
    "# m_pr_CNN1 = pd.read_csv('m_pr_results_CNN1.csv',delimiter=',')\n",
    "# m_pr_CNN1 = m_pr_CNN1[m_pr_CNN1['Unnamed: 0'].isin([0,2,6,9])]\n",
    "\n",
    "# m_rs_u2_CNN1 = pd.read_csv('m_rs_u2_results_CNN1.csv',delimiter=',')\n",
    "# m_rs_u2_CNN1 = m_rs_u2_CNN1[m_rs_u2_CNN1['Unnamed: 0'].isin([0,2,6,9])]\n",
    "\n",
    "# m_u2_tmax_CNN1 = pd.read_csv('m_u2_tmax_results_CNN1.csv',delimiter=',')\n",
    "# m_u2_tmax_CNN1 = m_u2_tmax_CNN1[m_u2_tmax_CNN1['Unnamed: 0'].isin([0,2,6,9])]\n",
    "\n",
    "frames = [u_CNN1, m_rs_CNN1, m_u2_CNN1, m_rh_CNN1, m_tmax_CNN1]#, m_tmin_CNN1, m_pr_CNN1, m_rs_u2_CNN1]\n",
    "result = pd.concat(frames, ignore_index=True)\n",
    "result['Unnamed: 0'] = result['Unnamed: 0'] + 1\n",
    "\n",
    "# plt.style.use('seaborn-paper')\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=[14,6], dpi=100)\n",
    "g1 = sns.boxplot(x=result.iloc[:,0], y=result.iloc[:,1], hue=result.iloc[:,2], data=result, palette=\"tab20\", linewidth=0.7, saturation=1)\n",
    "plt.tick_params(labelsize=12)\n",
    "# plt.xticks([1,3,7,10])\n",
    "plt.xlabel(\"Horizontes de previs√£o\", fontsize=14)\n",
    "plt.ylabel(\"RMSE\", fontsize=14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d87e67db777b4b0db676edb6578e0de57a75ced3517006e5561808a12abc48f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
